We agreed that we could collect relevant variables for the reference dataset of coups. Then we could decide what the actual analysis would look like.

# Coups
Combining Colpus and Coup d'etat (excluding conspiracy ones) datasets, from 2000 to 2020, we have 128 coups cases. From *Wikipedia*, we could collect the following variables for the coups: 

- names of the coups
- names of the president/coup leader
- is the coup leader from the military/police
- whether there are protests proceeding the coups
- whether coups are peaceful or not
- what are the reasons for the coups 
- what are the reactions of foreign actors (condemn? support? NA?)
- whether the coups are successful (did the leader exile or resign?)

These count as original data, and the **difficulty level** is (*).

# About the bias of the news reports: 
We could define it as report bias (counts) of coups. Possible ranges: 
- from 0 (no report) to 1; or
- from 0 to 30 (much attention)

**difficult level** (***): we need to match the news reports with the coup cases.

# About the sentiment coverage of the news reports:
## How to conceptualize delegitimize/legitimize
- whether there is a description of the social construct/hierarchy
- whether the sentiment is mobilizing
- whether there is mention of people's needs/grievances (water, electricity, power)
- whether there is a mention of the country's future (democratic backsliding/success/hope)

**difficult level** (*****): we need to make decisions and a very clear coding scheme for the four of us and the machine to understand human codings if we do framing analysis and scale it up.

